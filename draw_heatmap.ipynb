{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597604753202",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepared resnext model\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from skimage import io, transform\n",
    "\n",
    "import copy\n",
    "import os.path\n",
    "import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "plt.ion()   # interactive mode\n",
    "from matplotlib.pyplot import imshow\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        # torch.nn.MaxPool2d(kernel_size, stride, padding)\n",
    "        # input 維度 [3, 128, 128]\n",
    "        # our dimension [3,40,40]\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, 1, 1),  # [64, 20, 20]\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),      # [64, 10, 10]\n",
    "            nn.ZeroPad2d(1), # [64,12,12]\n",
    "    \n",
    "            nn.Conv2d(64, 128, 3, 1, 1), # [128, 12, 12]\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),      # [128, 6, 6]\n",
    "            nn.ZeroPad2d(1), # [128,8,8]\n",
    "    \n",
    "            nn.Conv2d(128, 256, 3, 1, 1), # [256, 8, 8]\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),      # [256, 4, 4]\n",
    " \n",
    "            nn.Conv2d(256, 512, 3, 1, 1), # [512, 8, 8]\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),       # [512, 2, 2]\n",
    "            \n",
    "#             nn.Conv2d(512, 512, 3, 1, 1), # [512, 4, 4]\n",
    "#             nn.BatchNorm2d(512),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2, 2, 0),       # [512, 2, 2]\n",
    "        )\n",
    "        self.cnn = nn.DataParallel(self.cnn)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512*2*2, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 4)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.cnn(x)\n",
    "        out = out.view(out.size()[0], -1)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ca = 4\n",
    "model_use='resnext'\n",
    "# use resnext model\n",
    "if model_use=='resnext':\n",
    "    model_ft = models.resnext50_32x4d(pretrained=False)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs,num_ca)\n",
    "elif model_use=='diy':\n",
    "    model_ft = Classifier()\n",
    "\n",
    "best_model_wts='./layers/resnext_model.p'\n",
    "model_ft.load_state_dict(torch.load(best_model_wts))\n",
    "model_ft.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_category(image):\n",
    "    # receives (M,N,3) image and returns predicted category\n",
    "    # print(np.shape(image),end='\\t')\n",
    "    data=torch.tensor(io.imread(image).transpose((2, 0, 1))).view(1,3,60,60)\n",
    "    outputs = model_ft(data.float())\n",
    "    # print(outputs)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    return preds.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_pixel(image):\n",
    "    # receives (M,N,3) image and returns predicted pixel\n",
    "    print(np.shape(image),end='\\t')\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_layer(draw=50,folder='layers',home='problem2',resize=0.02,crop_x=60,crop_y=60,cooling_alpha=0.001):\n",
    "    # create directory\n",
    "    if not os.path.exists('./%s'%(folder)): os.mkdir('./%s'%(folder))\n",
    "    if not os.path.exists('./%s/draw'%(folder)): os.mkdir('./%s/draw'%(folder))\n",
    "\n",
    "    # read label\n",
    "    layer='L%04d'%(draw)\n",
    "    mpm_dir='./%s/MPM/Layer%03dto%03d/%s/'%(home,(draw-1)//50*50+1,(draw-1)//50*50+50,layer)\n",
    "    pixel=[]\n",
    "    for temp in range(len(os.listdir(mpm_dir))):\n",
    "        name='%sframe_%04d.bmp'%(mpm_dir,temp+1)\n",
    "        pixel.append(np.sum(io.imread(name)>150))\n",
    "    threshold=np.array([10,np.quantile(pixel,.25),np.quantile(pixel,.75)])\n",
    "    category=[np.sum(temp>threshold) for temp in pixel]\n",
    "\n",
    "    # read cmd\n",
    "    cmd=pd.read_csv('./%s/Command_Part1/XYPT_Part01_%s.csv'%(home,layer),header=None)\n",
    "    left=cmd[0].min()\n",
    "    right=cmd[0].max()\n",
    "    down=cmd[1].min()\n",
    "    up=cmd[1].max()\n",
    "    mag=1000\n",
    "    width=int((right-left)*mag*resize)+1\n",
    "    height=int((up-down)*mag*resize)+1\n",
    "    power=np.zeros([width,height])\n",
    "    speed=np.zeros([width,height])\n",
    "    temporal=np.zeros([width,height])\n",
    "\n",
    "    current_order=0\n",
    "    locations=[]\n",
    "    loc_x=[]\n",
    "    loc_y=[]\n",
    "    first_row=cmd[0:1]\n",
    "    history_x=[first_row[0][0]]*3\n",
    "    history_y=[first_row[1][0]]*3\n",
    "    speed_max=-10000\n",
    "    speed_min=10000\n",
    "    for line in cmd.iterrows():\n",
    "        raw_x=line[1][0]\n",
    "        raw_y=line[1][1]\n",
    "        history_x.pop()\n",
    "        history_x.insert(0,raw_x)\n",
    "        history_y.pop()\n",
    "        history_y.insert(0,raw_y)\n",
    "        # calculate speed\n",
    "        last_speed=((history_x[2]-history_x[0])*(history_x[2]-history_x[0])+(history_y[2]-history_y[0])*(history_y[2]-history_y[0]))**0.5/2e-5\n",
    "        if current_order>0:\n",
    "            speed[current_x,current_y]=last_speed\n",
    "            speed_max=max(last_speed,speed_max)\n",
    "            speed_min=min(last_speed,speed_min)\n",
    "        current_order+=1\n",
    "        current_x=int((raw_x-left)*mag*resize)\n",
    "        current_y=int((raw_y-down)*mag*resize)\n",
    "        power[current_x,current_y]=line[1][2]\n",
    "        temporal[current_x,current_y]=current_order\n",
    "        if line[1][3]==2:\n",
    "            locations.append([current_x,current_y])\n",
    "            loc_x.append(raw_x)\n",
    "            loc_y.append(raw_y)\n",
    "    power_min=np.min(power)\n",
    "    power_max=np.max(power)\n",
    "    \n",
    "    # generate photos\n",
    "    photo_id=0\n",
    "    for temp in locations:\n",
    "        if photo_id%100==0: print(photo_id,end='\\t')\n",
    "        center_x,center_y=temp\n",
    "        power_crop=np.zeros([crop_x,crop_y])\n",
    "        speed_crop=np.zeros([crop_x,crop_y])\n",
    "        temporal_crop=np.zeros([crop_x,crop_y])\n",
    "        for x in range(center_x-int(crop_x*0.5),center_x+int(crop_x*0.5)):\n",
    "            for y in range(center_y-int(crop_y*0.5),center_y+int(crop_y*0.5)):\n",
    "                # consider locations in the window with time stamp earlier than center\n",
    "                if x<0 or x>=width: continue\n",
    "                if y<0 or y>=height: continue\n",
    "                if temporal[x,y]==0 or temporal[x,y]>temporal[center_x,center_y]: continue\n",
    "                # power crop\n",
    "                original_power=(power[x,y]-power_min)/(power_max-power_min)\n",
    "                power_crop[x+int(crop_x*0.5)-center_x,y+int(crop_y*0.5)-center_y]=int(original_power*255)\n",
    "                # speed crop\n",
    "                original_speed=(speed[x,y]-speed_min)/(speed_max-speed_min)\n",
    "                speed_crop[x+int(crop_x*0.5)-center_x,y+int(crop_y*0.5)-center_y]=int(original_speed*255)\n",
    "                # temporal crop\n",
    "                elapsed_time=temporal[center_x,center_y]-temporal[x,y]\n",
    "                temporal_crop[x+int(crop_x*0.5)-center_x,y+int(crop_y*0.5)-center_y]=int(np.exp(-elapsed_time*cooling_alpha)*255)\n",
    "        rgb_image=np.stack((power_crop.astype(np.uint8),speed_crop.astype(np.uint8),temporal_crop.astype(np.uint8)),axis=-1)\n",
    "        io.imsave('./%s/draw/%d.png'%(folder,photo_id),rgb_image,check_contrast=False)\n",
    "        photo_id+=1\n",
    "\n",
    "    pixel_results=[]\n",
    "    category_results=[]\n",
    "    for photo in range(photo_id):\n",
    "        if photo%100==0:print(photo,end='\\t')\n",
    "        img=predict_category('./%s/draw/%d.png'%(folder,photo))\n",
    "        # pixel_results.append(img)\n",
    "        # predict category\n",
    "        category_results.append(img)\n",
    "    # use quantiles to predict category\n",
    "    # threshold_results=np.array([10,np.quantile(pixel_results,.25),np.quantile(pixel_results,.75)])\n",
    "    # category_results=[np.sum(temp>threshold_results) for temp in pixel_results]\n",
    "    \n",
    "    # calculate accuracy\n",
    "    acc=sum(category[temp]==category_results[temp] for temp in range(len(category)))/len(category)\n",
    "    pd.DataFrame({'x':loc_x,'y':loc_y,\n",
    "                #   'pixel_label':pixel,\n",
    "                  'category_label':category,\n",
    "                #   'pixel_predict':pixel_results,\n",
    "                  'category_predict':category_results\n",
    "                  }).to_csv('./%s/heatmap_%d_%0.4f.csv'%(folder,draw,acc),index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for draw in range(1,251,10):\n",
    "    draw_layer(draw=draw)"
   ]
  }
 ]
}